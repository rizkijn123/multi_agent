# Online Gambling Comment Classification using Multi-Agent ML System

## Overview
This project implements a multi-agent system based on LLMs (GPT API) to build a text classification pipeline, specifically for online gambling comments. The system uses vertical collaboration among agents:

- **Recruiter Agent** – Selects the most relevant agents for a specific task.  
- **Pipeline Designer Agent** – Designs and improvises the ML pipeline based on goals and evaluator feedback.  
- **ML Engineer Agent** – Implements the pipeline, generates Python code, executes it, and handles errors adaptively.  
- **Evaluator Agent** – Evaluates the pipeline using standard classification metrics (Accuracy, F1 Score, Precision, Recall) and provides feedback for iterative improvements.  
- **Orchestrator** – Manages the workflow and iteration between agents and stops the process once the success criteria are met.  

## Requirements
- **Python 3.11**  
- Virtual environment (optional but recommended)  
- Python libraries (listed in `requirements.txt`):

Install dependencies:  
```bash
pip install -r requirements.txt
```

## Environment Setup
1. Create a `.env` file in the root of the project with the following content: OPENAI_API_KEY=your_openai_api_key_here
2. Make sure the dataset is located in the `data/` folder with the correct name used in the pipeline.

## How to Run

### Run the Main.py
Orchestrator manages the multi-agent workflow and pipeline iterations:
```bash
python main.py
```

## Logging and Output
- All execution logs are stored in `logs/agent_logs.txt`.  
- The latest pipeline strategy is saved in `logs/pipeline_strategy.json`.  
- Evaluator feedback is saved in `logs/evaluator_feedback.json`.  
- The ML pipeline code generated by the ML Engineer Agent is saved in `generated_ml_pipeline.py`.  

## Prompts
All prompts used by the agents are stored in the `prompts/` folder. Each agent has its own prompt file, for example:

- `prompts/prompt_recruiter.txt` – used by the Recruiter Agent to select relevant agents.  
- `prompts/prompt_pipeline_designer.txt` – used by the Pipeline Designer Agent to design and improve ML pipelines.  
- `prompts/prompt_ml_engineer.txt` – used by the ML Engineer Agent to generate Python code and handle execution errors.  
- `prompts/prompt_evaluator.txt` – used by the Evaluator Agent to evaluate pipelines and provide feedback.  

**Notes:**
- Prompts are written in natural language instructions for the LLM.  
- Make sure the prompt files exist and are correctly named in the `prompts/` folder, as the agents will read them at runtime.
